versionamento:

ollama --version


lista de modelos:

ollama ls

ollama list

baixar o modelo:

ollama pull  llama3.2:3b

Executar o modelo 
ollama run  llama3.2:3b

ollama run  llama3.2:3b "Explique Python em uma frase"

criar API

curl http://localhost:11434/api/generate -d '{ "model": "llama3.2:3b","prompt": "Explique buracos negros em poucas palavras" }'

Invoke-WebRequest -Uri "http://localhost:11434/api/generate" -Method POST -Body '{ "model": "llama3.2:3b", "prompt": "Explique buracos negros"}' -Cont

Stopar
/bye

ollama stop llama3.2:3b


Ver que modelo esta sendo executado:
ollama ps


Apagar modelo
ollama rm llama3.2:3b

